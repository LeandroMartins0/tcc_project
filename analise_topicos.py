import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation as LDA
from nltk.corpus import stopwords
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
nltk.download('stopwords')
from wordcloud import WordCloud

sns.set_style("whitegrid")

def show_topic_analysis(df):

    st.title("üìö An√°lise de T√≥picos")
    
    st.write("""
    Descubra os principais t√≥picos discutidos nos coment√°rios das redes sociais. Esta se√ß√£o ajuda a identificar padr√µes e assuntos frequentes no seu p√∫blico.
    """)

    # Entendendo a An√°lise de T√≥picos
    st.write("""
    ### üîç Entendendo a An√°lise de T√≥picos:

    - **üìñ T√≥picos**: Grupos de palavras que geralmente aparecem juntas e representam um tema espec√≠fico.
    
    - **üõ†Ô∏è LDA**: T√©cnica estat√≠stica que identifica padr√µes de palavras para classificar textos em t√≥picos.
    """)

    # Processando os t√≥picos
    st.header("üîé Descobrindo os T√≥picos")
    
    stop_words = stopwords.words('portuguese')
    count_vectorizer = CountVectorizer(stop_words=stop_words, max_df=0.9, min_df=2, max_features=1000)
    term_matrix = count_vectorizer.fit_transform(df['comentario'])
    
    lda = LDA(n_components=5, random_state=42)
    lda.fit(term_matrix)

    # Nomes gen√©ricos para os t√≥picos
    topic_names = ["T√≥pico 1", "T√≥pico 2", "T√≥pico 3", "T√≥pico 4", "T√≥pico 5"]

    # Mostrando wordcloud para cada t√≥pico
    for idx, topic in enumerate(lda.components_):
        st.write(f"### üìå **{topic_names[idx]}**")
        cloud = WordCloud(stopwords=stop_words, background_color="white", max_words=10).generate_from_frequencies({count_vectorizer.get_feature_names_out()[i]: topic[i] for i in topic.argsort()[-10:]})
        plt.imshow(cloud, interpolation='bilinear')
        plt.axis('off')
        st.pyplot(plt.gcf())
        plt.clf()

    st.header("üìä Distribui√ß√£o dos T√≥picos")
    topic_values = lda.transform(term_matrix)
    df['topico'] = [topic_names[i] for i in topic_values.argmax(axis=1)]

    sns.countplot(data=df, x='topico', palette='viridis', order=topic_names)
    plt.title('Distribui√ß√£o de Coment√°rios por T√≥pico')
    plt.ylabel('N√∫mero de Coment√°rios')
    plt.xlabel('T√≥pico')
    st.pyplot(plt.gcf())
    plt.clf()

    # Como utilizar os insights
    st.header("üíº Como Utilizar os Insights")

    st.write("""
    - **Planejamento de Conte√∫do**: Identifique t√≥picos populares e crie conte√∫do voltado para esses temas.
    
    - **Engajamento do Cliente**: Enderece preocupa√ß√µes ou t√≥picos frequentemente discutidos para melhorar o engajamento.
    
    - **Desenvolvimento de Produto**: Use feedback tem√°tico para inspirar novos recursos ou produtos.
    
    - **Estrat√©gia de Marketing**: Ajuste as campanhas publicit√°rias com base nos t√≥picos que ressoam com sua audi√™ncia.
    
    A an√°lise de t√≥picos √© uma ferramenta rica. Use-a para entender as necessidades e interesses do seu p√∫blico e tomar decis√µes informadas.
    """)

# show_topic_analysis(df)
